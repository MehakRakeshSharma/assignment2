Assignment-53: A Job Ready Bootcamp in c++,DSA and IOT

Time Complexity

1. What is the time, and space complexity of the following code:

int a = 0, b = 0;
for (i = 0; i < N; i++) {
a = a + rand();
}
for (j = 0; j < M; j++) {
b = b + rand();
}

ans1 )

Time Complexity:

The first for loop runs N times, where N is the loop limit. Inside the loop, the statement "a = a + rand()" executes, which involves generating a random number and adding it to the variable 'a'. The time complexity of generating a random number is typically considered to be O(1). Therefore, the time complexity of the first loop is O(N).

The second for loop runs M times, where M is the loop limit. Inside the loop, the statement "b = b + rand()" executes, which also involves generating a random number and adding it to the variable 'b'. Similarly, the time complexity of generating a random number is O(1). Therefore, the time complexity of the second loop is O(M).

Overall, the time complexity of the given code is O(N + M), where N and M are the loop limits for the first and second loops, respectively.

Space Complexity:
The space complexity of the given code is determined by the variables used. In this case, there are two variables 'a' and 'b' of type int. Therefore, the space complexity is O(1) since the space required for storing these variables does not depend on the input size.

In summary, the time complexity of the code is O(N + M), and the space complexity is O(1).

/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

2. What is the time complexity of the following code:
int a = 0;
for (i = 0; i < N; i++) {
for (j = N;j > i; j--) {
a = a + i + j;
}
}

ans 2 )


The time complexity of the given code can be analyzed as follows:

The outer loop runs N times, where N is the loop limit. Inside the outer loop, there is an inner loop that also runs N times, but with a decreasing range from N to i. In each iteration of the inner loop, the statement "a = a + i + j" executes, which involves adding the values of 'i' and 'j' to the variable 'a'.

Let's analyze the number of iterations of the inner loop for each iteration of the outer loop:

For the first iteration of the outer loop, the inner loop runs N times.
For the second iteration of the outer loop, the inner loop runs N-1 times.
For the third iteration of the outer loop, the inner loop runs N-2 times.
...
For the last iteration of the outer loop, the inner loop runs 1 time.
Therefore, the total number of iterations of the inner loop can be expressed as the sum of the first N natural numbers:

N + (N-1) + (N-2) + ... + 1

This sum can be simplified using the formula for the sum of an arithmetic series:

Sum = (N * (N + 1)) / 2

Hence, the total number of iterations of the inner loop is (N * (N + 1)) / 2.

Since the statement inside the inner loop has a constant time complexity, the overall time complexity of the code can be approximated as O(N^2).

Therefore, the time complexity of the given code is O(N^2).

///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////


3. What is the time complexity of the following code:
int i, j, k = 0;
for (i = n / 2; i <= n; i++) {
for (j = 2; j <= n; j = j * 2) {
k = k + n / 2;
}
}


ans 3 )

The time complexity of the given code can be analyzed as follows:

The outer loop runs from n/2 to n, with i incrementing by 1 in each iteration. The number of iterations of the outer loop can be approximated as n/2.

Inside the outer loop, there is an inner loop that runs from 2 to n, with j doubling in each iteration (j = j * 2). The number of iterations of the inner loop can be approximated as log(n).

The statement inside the inner loop, "k = k + n/2", has a constant time complexity of O(1).

Therefore, the overall time complexity of the code can be approximated as O((n/2) * log(n)).

Simplifying further, we can ignore the constant factor of 1/2, so the time complexity can be simplified to O(n * log(n)).

Hence, the time complexity of the given code is O(n * log(n)).

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////


4. What is the time complexity of the following code :
void fun(int n)
{
for (int i = 0; i < n / 2; i++)
for (int j = 1; j + n / 2 <= n; j++)
for (int k = 1; k <= n; k = k * 2)
cout << "Prateek Jain";
}

ans 4 )

The time complexity of the given code can be analyzed as follows:

The outermost loop runs from 0 to n/2 - 1, with i incrementing by 1 in each iteration. The number of iterations of the outermost loop is approximately n/2.

Inside the outermost loop, there is a nested loop. The second loop runs from 1 to n - n/2, with j incrementing by 1 in each iteration. The number of iterations of the second loop is approximately n - n/2.

Inside the second loop, there is another nested loop. The third loop runs from 1 to n, with k doubling in each iteration (k = k * 2). The number of iterations of the third loop can be approximated as log(n).

The statement inside the innermost loop, "cout << 'Prateek Jain'", has a constant time complexity of O(1).

Therefore, the overall time complexity of the code can be approximated as O((n/2) * (n - n/2) * log(n)).

Simplifying further, we can ignore the constant factors and simplify the expression:

O((n/2) * (n - n/2) * log(n))
= O(n^2 * log(n))

Hence, the time complexity of the given code is O(n^2 * log(n)).

/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

5. T (n) = 3T (n/3) + n/2

ans 5 )

To determine the runtime expression using the Master Theorem, we need to compare the given recurrence with the standard form: T(n) = aT(n/b) + f(n).

In this case:

a = 3 (the number of recursive subproblems)
b = 3 (the size of each subproblem)
f(n) = n/2 (the time complexity of the non-recursive part)
Now, let's compare the values of n^(log_b(a)) and f(n) to determine the case.

If f(n) is asymptotically smaller than n^(log_b(a)), which means f(n) = O(n^(log_b(a - ε))) for some ε > 0, then the runtime is dominated by the recursive part.
In our case, n^(log_b(a)) = n^(log_3(3)) = n, and f(n) = n/2. Since n/2 is not asymptotically smaller than n, this case doesn't apply.

If f(n) is asymptotically larger than n^(log_b(a)), which means f(n) = Ω(n^(log_b(a + ε))) for some ε > 0, and if a * f(n/b) ≤ c * f(n) for some constant c < 1 and sufficiently large n, then the runtime is dominated by the non-recursive part.
In our case, n^(log_b(a)) = n^(log_3(3)) = n, and f(n) = n/2. Since n/2 is not asymptotically larger than n, this case doesn't apply.

If f(n) has the same asymptotic growth rate as n^(log_b(a)) multiplied by a polynomial factor, which means f(n) = Θ(n^(log_b(a)) * log^k(n)) for some k ≥ 0, then the runtime is dominated by both the recursive and non-recursive parts.
In our case, n^(log_b(a)) = n^(log_3(3)) = n, and f(n) = n/2. Since n/2 has the same asymptotic growth rate as n * log^0(n), this case applies.

Therefore, using the Master Theorem, the runtime expression for T(n) = 3T(n/3) + n/2 is:

T(n) = Θ(n * log(n) * log^0(n)) = Θ(n * log(n))

So, the runtime complexity of the given recurrence relation is Θ(n * log(n)).

///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

6. T (n) = 6T (n/3) + n^2log n

ans 6 )

T(n) = 6T(n/3) + n^2log(n)
In this case:

a = 6
b = 3
f(n) = n^2log(n)
The value of n^(log_b(a)) is n^(log_3(6)). Since log_3(6) is approximately 1.631, n^(log_3(6)) is n^(1.631).

The function f(n) = n^2log(n) is not asymptotically smaller or larger than n^(log_3(6)), and it does not have the same growth rate multiplied by a polynomial factor. Therefore, the Master Theorem cannot be applied to this recurrence directly

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

7. T (n) = 4T (n/2) + n/ log n

ans 7 )

In this case:

a = 4
b = 2
f(n) = n/ log(n)
The value of n^(log_b(a)) is n^(log_2(4)), which is n^2.

The function f(n) = n/ log(n) is not asymptotically larger than n^2, but it does have the same growth rate multiplied by a polynomial factor. Therefore, this recurrence falls under case 3 of the Master Theorem.

The runtime expression for T(n) = 4T(n/2) + n/ log(n) is:

T(n) = Θ(n^2 * log^1(n)) = Θ(n^2 * log(n)).

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

8. T (n) = 64T (n/8) − n^2log n

ans 8 )

In this case:

a = 64
b = 8
f(n) = -n^2log(n)
Since the function f(n) is negative, the Master Theorem does not apply. The recurrence relation needs to be analyzed using a different method.

///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

9. T (n) = 7T (n/3) + n^2

ans 9 )

In this case:

a = 7
b = 3
f(n) = n^2
The value of n^(log_b(a)) is n^(log_3(7)).

The function f(n) = n^2 is not asymptotically larger than n^(log_3(7)) and does not have the same growth rate multiplied by a polynomial factor. Therefore, the Master Theorem cannot be applied directly.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

10. T (n) = 4T (n/2) + log n

ans 10 )



Let's analyze each of the recurrences using the Master Theorem:

T(n) = 6T(n/3) + n^2log(n)
In this case:

a = 6
b = 3
f(n) = n^2log(n)
The value of n^(log_b(a)) is n^(log_3(6)). Since log_3(6) is approximately 1.631, n^(log_3(6)) is n^(1.631).

The function f(n) = n^2log(n) is not asymptotically smaller or larger than n^(log_3(6)), and it does not have the same growth rate multiplied by a polynomial factor. Therefore, the Master Theorem cannot be applied to this recurrence directly.

T(n) = 4T(n/2) + n/ log(n)
In this case:

a = 4
b = 2
f(n) = n/ log(n)
The value of n^(log_b(a)) is n^(log_2(4)), which is n^2.

The function f(n) = n/ log(n) is not asymptotically larger than n^2, but it does have the same growth rate multiplied by a polynomial factor. Therefore, this recurrence falls under case 3 of the Master Theorem.

The runtime expression for T(n) = 4T(n/2) + n/ log(n) is:

T(n) = Θ(n^2 * log^1(n)) = Θ(n^2 * log(n)).

T(n) = 64T(n/8) - n^2log(n)
In this case:

a = 64
b = 8
f(n) = -n^2log(n)
Since the function f(n) is negative, the Master Theorem does not apply. The recurrence relation needs to be analyzed using a different method.

T(n) = 7T(n/3) + n^2
In this case:

a = 7
b = 3
f(n) = n^2
The value of n^(log_b(a)) is n^(log_3(7)).

The function f(n) = n^2 is not asymptotically larger than n^(log_3(7)) and does not have the same growth rate multiplied by a polynomial factor. Therefore, the Master Theorem cannot be applied directly.

T(n) = 4T(n/2) + log(n)
In this case:

a = 4
b = 2
f(n) = log(n)
The value of n^(log_b(a)) is n^(log_2(4)), which is n^2.

The function f(n) = log(n) is asymptotically smaller than n^2. However, it does not have the same growth rate multiplied by a polynomial factor. Therefore, the Master Theorem cannot be applied directly.